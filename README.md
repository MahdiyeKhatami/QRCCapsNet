# QRCCapsNet
Fashion Image Retrieval With Quadruplet Capsule Networks

Official Notebook for QRCCapsNet Based on https://github.com/MahdiyeKhatami/QRCCapsNet/blob/main/Khatami_Fashion_Image_Retrieval_With_Quadruplet_Capsule_Networks.pdf

![myimage-alt-tag](https://i.postimg.cc/wM85JMdy/15.png)

# Abstract
The purpose of fashion image retrieval is to find images similar to the image searched in online shopping. one of the challenges is to retrieval images without sensitivity to the viewing angle and without using additional information. In previous studies, the RCCapsNet architecture has been proposed with the aim of replacing capsule networks with convolutional neural networks to solve the mentioned problems, which has used the triplet loss function to achieve this. This research is done with the aim of improving the RCCapsNet. To achieve this, the quadruplet version of the RCCapsNet is proposed using the quadruplet loss function which is named as QRCCapsNet. The proposed method is trained on the DeepFashion-Inshop dataset and the performance is evaluated by Recall@K metric. The results indicate the success of our proposed method

Keywords: fashion image retrieval, in-shop clothing retrieval, capsule networks, quadruplet loss function

# Refrences

[1] F. Kinli, B. Ozcan, F. Kirac, ["Fashion Image Retrieval with Capsule Networks, "](https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Kinli_Fashion_Image_Retrieval_with_Capsule_Networks_ICCVW_2019_paper.pdf)Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2019 
[2] S. Sabour, N. Frosst, and G. E. Hinton. ["Dynamic routing between capsules,]"(https://arxiv.org/pdf/1710.09829.pdf) In Advances in Neural Information Processing Systems 30, pages 3856–3866. 2017.
[3] W. Chen, X. Chen, J. Zhang and K. Huang, ["Beyond Triplet Loss: A Deep Quadruplet Network for Person Re-identification,"](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chen_Beyond_Triplet_Loss_CVPR_2017_paper.pdf)  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 1320-1329, doi: 10.1109/CVPR.2017.145.
[4] Y. Miao, G. Li, C. Bao, J. Zhang and J. Wang, ["ClothingNet: Cross-Domain Clothing Retrieval With Feature Fusion and Quadruplet Loss,"]([https://link-url-here.org](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9154357)) in IEEE Access, vol. 8, pp. 142669-142679, 2020, doi: 10.1109/ACCESS.2020.3013631.
[5] Z. Liu, P. Luo, S. Qiu, X. Wang, and X. Tang, [“DeepFashion: Powering robust clothes recognition and retrieval with rich annotations,”]([https://link-url-here.org](https://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/InShopRetrieval.html)) in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.


# Contact 
mahdiye_khatami@semnan.ac.ir, m.khatami95@gmail.com
